{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project IV - Wrangle and Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Gathering Data](#gathering)\n",
    "- [Part II - Assessing Data](#assessing)\n",
    "- [Part III - Cleaning Data](#cleaning)\n",
    "- [Part IV - Analyzing Data](#analyzing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "### (I)- Introduction\n",
    "\n",
    "The dataset that we will be wrangling (and analyzing and visualizing) is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because \"they're good dogs Brent.\" WeRateDogs has over 4 million followers and has received international media coverage.\n",
    "\n",
    "**Our goal:** wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gathering'></a>\n",
    "### (II)- Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would be gathering data from three different sources in three different formats. The three data pieces of information are following:\n",
    "\n",
    "1) **WeRateDogs Twitter Archive**- This file is provided to us. We will download it manually and fetch it in our project. This file is in `.csv` format and the name of the file is `twitter_archive_enhanced.csv`. This  file contains basic information about the tweets like like tweet ids, timestamp of tweets, sources, names of dog etc.\n",
    "\n",
    "2) **Tweet Image Predictions File**: This file is about breeds of dogs i.e. what breed of dog (or other object, animal, etc.) is present in each tweet according to a neural network. This file is in `.tsv` format and  the name of the file is `image_predictions.tsv`. It is hosted on Udacity's servers. We would download it programmatically using the Requests library from the following URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\n",
    "\n",
    "3) **Retweet and Favorite Count File**- `twitter_archive_enhanced.csv` file does not include two important data attributes which are retweet and favorite count of a tweet. So in order to  get these two attributes, we would be using Python's Tweepy library. We would be using tweet IDs in the WeRateDogs Twitter archive, query the Twitter API for each tweet's JSON data and store each tweet's entire set of JSON data in a file called `tweet_json.txt` file. Each tweet's JSON data would be written to its own line. Then we will read this .txt file line by line into a pandas DataFrame with (at minimum) tweet ID, retweet count, and favorite count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import requests\n",
    "import tweepy \n",
    "import json\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Data File: `twitter_archive_enhanced.csv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading archive file 'twitter_archive_enhanced.csv'\n",
    "twitter_archive=pd.read_csv('twitter_archive_enhanced.csv')\n",
    "twitter_archive.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Data File: `image_predictions.tsv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading file's content programmaticaly and saving it into a file 'image_predictions.tsv'.\n",
    "url='https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response=requests.get(url)\n",
    "\n",
    "with open ('./image_predictions.tsv', 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the content of the file in a dataframe\n",
    "image_predictions=pd.read_csv('image_predictions.tsv',sep='\\t')\n",
    "image_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Data File: `tweet_json.txt`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathering data from Twitter using Tweepy libraray and saving it in tweet_json.txt file.\n",
    "\n",
    "\n",
    "#1) setting up tweepy object\n",
    "\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_secret = ''\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) collecting tweet IDs from archive and putting them into a list 'tweet_ids' \n",
    "\n",
    "tweet_ids=list(twitter_archive['tweet_id'])\n",
    "tweet_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3)now fetching two missing attributes corresponding to tweet ids\n",
    "\n",
    "\n",
    "#list for tweet ids which will not be accessible.\n",
    "errorneous_ids=[]\n",
    "\n",
    "with open('tweet_json.txt','w') as file:\n",
    "\n",
    "    for _id in tweet_ids:\n",
    "\n",
    "        try:\n",
    "            \n",
    "            #fetching data corresponding to tweet ID\n",
    "            t_data=api.get_status(_id,tweet_mode='extended',wait_on_rate_limit = True, wait_on_rate_limit_notify = True)\n",
    "\n",
    "            #t_data is not in JSON serializable form, converting it into this format\n",
    "            json_content=t_data._json\n",
    "\n",
    "            #putting json content in the text file\n",
    "            json.dump(json_content,file)\n",
    "            file.write('\\n')\n",
    "        \n",
    "        except Exception as e:\n",
    "                \n",
    "            #saving id in the list errorneous \n",
    "            errorneous_ids.append(_id)\n",
    "\n",
    "#displaying ids which were not accessible.`\n",
    "errorneous_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) Reading json content from 'tweet_json.txt' file and extracting rewteet and fav count for each tweet_ids\n",
    "\n",
    "\n",
    "#list for saving dictionaries\n",
    "dict_list=[]\n",
    "\n",
    "\n",
    "with open('tweet_json.txt','r') as file:\n",
    "    for tweet_data in file:\n",
    "        \n",
    "        #converting tweet_data in dict format:\n",
    "        tweet_data=json.loads(tweet_data)\n",
    "        \n",
    "        #creating dictionary,saving both attributes  in it and appending it in 'dict_list'\n",
    "        dict_list.append({\n",
    "            \n",
    "                        'tweet_id': tweet_data['id'],\n",
    "                        'retweet_count': tweet_data['retweet_count'],\n",
    "                        'favorite_count': tweet_data['favorite_count'],\n",
    "                         \n",
    "                         })\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) converting list of dictionary in a dataframe\n",
    "\n",
    "retweet_fav_counts=pd.DataFrame(dict_list, columns=['tweet_id','favorite_count','retweet_count'])\n",
    "retweet_fav_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assessing'></a>\n",
    "### (III)- Assessing Data\n",
    "\n",
    "Assessment of data can be done in two ways: 1) Visually 2) Programmatically.\n",
    "\n",
    "We will be observing our data in both ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assessing `twitter_archive` dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual Assessment\n",
    "twitter_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking columns names, their datatype and count of non-null values\n",
    "twitter_archive.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Columns Description:**\n",
    "\n",
    "*    **tweet_id:** the unique identifier for each tweet.\n",
    "*    **in_reply_to_status_id:** if the represented Tweet is a reply, this field will contain the integer representation of the original Tweet’s ID\n",
    "*    **in_reply_to_user_id:** if the represented Tweet is a reply, this field will contain the integer representation of the original Tweet’s author ID\n",
    "*    **timestamp:** time when tweet was created\n",
    "*    **source:** utility used to post the Tweet, as an HTML-formatted string. e.g. Twitter for Android, Twitter for iPhone, Twitter Web Client\n",
    "*    **text:** actual UTF-8 text of the status update\n",
    "*    **retweeted_status_id:** if the represented Tweet is a retweet, this field will contain the integer representation of the original Tweet’s ID\n",
    "*    **retweeted_status_user_id:** if the represented Tweet is a retweet, this field will contain the integer representation of the original Tweet’s author ID\n",
    "*    **retweeted_status_timestamp:** time of retweet\n",
    "*    **expanded_urls:** tweet URL\n",
    "*    **rating_numerator:** numerator of the rating of a dog.\n",
    "*    **rating_denominator:** denominator of the rating of a dog.\n",
    "*    **doggo:** one of the 4 dog \"stages\"\n",
    "*    **floofer:** one of the 4 dog \"stages\"\n",
    "*    **pupper:** one of the 4 dog \"stages\"\n",
    "*    **puppo:** one of the 4 dog \"stages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking properties of the table\n",
    "twitter_archive.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if any duplicated tweet ID is present in the dataset\n",
    "twitter_archive.tweet_id.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding tweets which are retweeted and their count\n",
    "retweets=twitter_archive[~twitter_archive.retweeted_status_id.isnull()]\n",
    "retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting no. of retweets which are in the dataframe \n",
    "retweets.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking values of rating_numerator feature and their counts\n",
    "twitter_archive.rating_numerator.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking value of rating_demominator features and their counts\n",
    "twitter_archive.rating_denominator.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the names and their counts\n",
    "twitter_archive.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking doggo columns values and their counts\n",
    "twitter_archive.doggo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking floofer columns values and their counts\n",
    "twitter_archive.floofer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking pupper columns values and their counts\n",
    "twitter_archive.pupper.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking puppo columns values and their counts\n",
    "twitter_archive.puppo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rows in which at least one dog \"stage\" is present\n",
    "dog_stages=twitter_archive[~(twitter_archive.doggo=='None') | ~(twitter_archive.pupper=='None') \n",
    "                | ~(twitter_archive.puppo=='None') |~(twitter_archive.floofer=='None')].iloc[:,[0,13,14,15,16]]\n",
    "\n",
    "dog_stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rows where multiple dog \"stages\" are present\n",
    "\n",
    "#replacing none to null value\n",
    "dog_stages['doggo']=dog_stages.doggo.replace('None',np.nan)\n",
    "dog_stages['floofer']=dog_stages.floofer.replace('None',np.nan)\n",
    "dog_stages['pupper']=dog_stages.pupper.replace('None',np.nan)\n",
    "dog_stages['puppo']=dog_stages.puppo.replace('None',np.nan)\n",
    "\n",
    "#dropping the rows where only one non-null value exits\n",
    "dog_stages.dropna(axis=0, how='any', thresh=3,inplace=True)\n",
    "dog_stages.iloc[:,[0,1,2,3,4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Assessing `image-predictions.csv` dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual assessment\n",
    "image_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking columns names, their datatype and count of non-null values\n",
    "image_predictions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*    **tweet_id:** is the last part of the tweet URL after \"status\"\n",
    "*    **p1:** is the algorithm's #1 prediction for the image in the tweet → golden retriever\n",
    "*    **p1:**_conf is how confident the algorithm is in its #1 prediction → 95%\n",
    "*    **p1_dog:** is whether or not the #1 prediction is a breed of dog → TRUE\n",
    "*    **p2:** is the algorithm's second most likely prediction → Labrador retriever\n",
    "*    **p2_conf:** is how confident the algorithm is in its #2 prediction → 1%\n",
    "*    **p2_dog:** is whether or not the #2 prediction is a breed of dog → TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking properties of the dataframe\n",
    "image_predictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking values of p1 and counts\n",
    "image_predictions.p1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking values of p2 and counts\n",
    "image_predictions.p2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking values of p2 and counts\n",
    "image_predictions.p3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicated urls\n",
    "with pd.option_context('max_colwidth',200):\n",
    "    display(image_predictions[image_predictions['jpg_url'].duplicated(keep=False)].sort_values('jpg_url'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Note:\n",
    "In the above result, although there are duplicated url presents, we won't be deleting them as they belong to different tweet ids.It means one of them could be original tweet and one of them could be retweeted tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assessing `retweet_fav_counts` dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual assessment\n",
    "retweet_fav_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking columns names, their da`otatype and count of non-null values\n",
    "retweet_fav_counts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking properties of the dataframe\n",
    "retweet_fav_counts.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quality Issues:**\n",
    "\n",
    "**1) `tweeter-archive` dataframe:**\n",
    "\n",
    "  a) Retweets need to be deleted.\n",
    " \n",
    "  b) Features which are not required can be removed.\n",
    "\n",
    "  c) Data type needs to be changed of these columns: \n",
    "  *  `tweet_id`: int->str, \n",
    "  * `in_reply_to_status_id`: float->str, \n",
    "  * `in_reply_to_user_id`: float->str, \n",
    "  * `timestamp`: object->datetime , \n",
    "  * `rating_numerator`: int->float.\n",
    "\n",
    " \n",
    "  d) Ratings, which were provided in decimal values, are not properly fetched.\n",
    "\n",
    "  e)  In some instances, when two fractional parts (#/#) are given in the text, it takes the first fractional part as rating but it is found found that rating is present in second fractional part.\n",
    "\n",
    "  f) Errorneous names starting with lowercase letters. For example: a, an, officially etc. need to be removed and set as none.\n",
    "\n",
    "  g) Sources are difficult to read.\n",
    "  \n",
    "  h) 'None' values in the dataframe.\n",
    "  \n",
    "  \n",
    "\n",
    "$$$$\n",
    "\n",
    "**2) `image_predictions` dataframe:**: \n",
    "\n",
    "i) Some of the values in p1, p2 and p3 features start with uppercase letter and some of them in lowercase letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tidiness Issues:**\n",
    "\n",
    "**1)**   Merge dog \"stages\" column in one column.\n",
    "\n",
    "**2)**   Add 'retweet_count' and 'favorite_count' features from `retweet_fav_counts` dataframe to `twitter_archive` dataframe.\n",
    "\n",
    "**3)**   Add prediction data from `image_predictions` dataframe to `twitter_archive` dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleaning'></a>\n",
    "### (IV)- Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating copies of dataframe\n",
    "twitter_archive_clean=twitter_archive.copy()\n",
    "image_predictions_clean=image_predictions.copy()\n",
    "retweet_fav_counts_clean=retweet_fav_counts.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retweets need to be deleted.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Define:_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only original tweets in `tweet_archive_clean` dataframe. Delete retweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_code:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying retweets.\n",
    "twitter_archive_clean[~twitter_archive.retweeted_status_id.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping retweets\n",
    "twitter_archive_clean=twitter_archive_clean[twitter_archive_clean.retweeted_status_id.isnull()]\n",
    "twitter_archive_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_test:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying retweets again.\n",
    "twitter_archive_clean[~twitter_archive.retweeted_status_id.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge dog \"stages\" column in one column.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Define:_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create one column for dog stages which stores values from columns 'doggo', 'floofer', 'pupper', 'puppo' together except none values.\n",
    "To do this:\n",
    "*   Melt 'doggo', 'floofer', 'pupper', 'puppo' columns.\n",
    "*   Create a new dataframe 'df_dog_stages' which holds tweets ids and all the dog stages associated with it.\n",
    "*   Drop 'dog_stages' column present in 'twitter_archive_clean' dataframe.\n",
    "*   Merge 'df_dog_stages' dataframe and twitter_archive_clean' dataframe and remove duplicates.\n",
    "*   If multiple dog stages are present for tweets, then check text associated with these tweets and choose an appropriate dog stage. Then correct it manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Code:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's check what is the shape of 'twitter_archive_clean' dataframe at this point\n",
    "twitter_archive_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Melting four columns 'doggo','floofer','pupper','puppo'\n",
    "\n",
    "\n",
    "all_columns=list(twitter_archive_clean)\n",
    "value_vars=['doggo','floofer','pupper','puppo']\n",
    "id_vars=[x for x in all_columns if x not in value_vars]\n",
    "\n",
    "twitter_archive_clean=twitter_archive_clean.melt(id_vars=id_vars,value_vars=value_vars,value_name='dog_stages')\n",
    "\n",
    "#dropping 'variable' column\n",
    "twitter_archive_clean.drop(columns='variable',axis=1,inplace=True)\n",
    "\n",
    "#Let's see how it looks like now\n",
    "twitter_archive_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Creating a dataframe for tweet ids and associated all the dog stages with it by using group by function.\n",
    "\n",
    "\n",
    "#grouping by 'tweet_id' column\n",
    "grouped=twitter_archive_clean.groupby('tweet_id')['dog_stages']\n",
    "\n",
    "#collecting dog_stage values of tweet ids together and removing 'None' from them\n",
    "dict1=[]\n",
    "for tweet_id, list_of_dog_stages in grouped:\n",
    "    \n",
    "    str1=\"\"\n",
    "    \n",
    "    for stage in list_of_dog_stages:\n",
    "        if stage!='None':str1=str1+stage+', '\n",
    "\n",
    "    dict1.append({\n",
    "        'tweet_id':tweet_id,\n",
    "        'dog_stages':str1[:-2]\n",
    "                })\n",
    "    \n",
    "\n",
    "#converting dictionary into dataframe\n",
    "df_dog_stages=pd.DataFrame(dict1,columns=['tweet_id','dog_stages'])\n",
    "\n",
    "#replacing empty string to 'None'\n",
    "df_dog_stages.dog_stages=df_dog_stages.dog_stages.replace('','None')\n",
    "\n",
    "#let's look at the dataframe now\n",
    "df_dog_stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Now we have a dataframe with tweet ids and associated dog stages with it(dataframe: 'df_dog_stages' ). We would like to \n",
    "#merge it with dataframe 'twitter_archive_clean'. But beofre merging both dataframes, we would want to delete 'dog_stages\n",
    "#column present in 'twitter_archive_clean' as it will no longer useful for us.\n",
    "\n",
    "\n",
    "#droping 'dog_stages' column from 'twitter_archive_clean'\n",
    "twitter_archive_clean.drop(columns=['dog_stages'],axis=1,inplace=True)\n",
    "twitter_archive_clean\n",
    "\n",
    "#now merging both the dataframes on 'tweet_id'\n",
    "twitter_archive_clean=twitter_archive_clean.merge(df_dog_stages,on='tweet_id',how='inner')\n",
    "\n",
    "twitter_archive_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) In 'twitter_archive_clean'there are 4 rows for each 'tweet_id', eliminating all duplicated rows now\n",
    "twitter_archive_clean.drop_duplicates(subset=['tweet_id'],inplace=True)\n",
    "twitter_archive_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) Now let's have a look at the tweets where multiple dog stages are present. We will check the text of these tweets \n",
    "#and choose appropriate dog stages. In case of ambiguous data, we will set it to None.\n",
    "\n",
    "with pd.option_context('max_colwidth', 200):\n",
    "    display(twitter_archive_clean[(twitter_archive_clean.dog_stages!='doggo') &\\\n",
    "                      (twitter_archive_clean.dog_stages!='floofer') &\\\n",
    "                      (twitter_archive_clean.dog_stages!='pupper') &\\\n",
    "                      (twitter_archive_clean.dog_stages!='puppo')&\\\n",
    "                      (twitter_archive_clean.dog_stages!='None')].iloc[:,[0,5,13]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #correcting dog_stages manually\n",
    "twitter_archive_clean.loc[660,'dog_stages']='puppo'\n",
    "twitter_archive_clean.loc[688,'dog_stages']='None'   #ambiguous text\n",
    "twitter_archive_clean.loc[1528,'dog_stages']='pupper'\n",
    "twitter_archive_clean.loc[1768,'dog_stages']='None'  #ambiguous text\n",
    "twitter_archive_clean.loc[1868,'dog_stages']='None'  #ambiguous text\n",
    "twitter_archive_clean.loc[1896,'dog_stages']='pupper'\n",
    "twitter_archive_clean.loc[2268,'dog_stages']='doggo'\n",
    "twitter_archive_clean.loc[2372,'dog_stages']='None'  #ambiguous text\n",
    "twitter_archive_clean.loc[2888,'dog_stages']='None'  #ambiguous text\n",
    "twitter_archive_clean.loc[3124,'dog_stages']='None'  #ambiguous text\n",
    "twitter_archive_clean.loc[3540,'dog_stages']='None'  #ambiguous text\n",
    "twitter_archive_clean.loc[3740,'dog_stages']='None'  #ambiguous text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Test:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's have a look on the dataframe now\n",
    "twitter_archive_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's look at columns of 'twitter_archive_clean' dataframe\n",
    "twitter_archive_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape of 'twitter_archive_clean' dataframe\n",
    "twitter_archive_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's look at the values of 'dpg_stages' column\n",
    "twitter_archive_clean.dog_stages.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Add two columns: retweet_count and fav_count from `retweet_fav_counts` dataframe to `twitter_archive` dataframe.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Define:_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge both the dataframes on 'tweet_id' column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Code:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean=twitter_archive_clean.merge(retweet_fav_counts_clean,how='inner',on='tweet_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Test:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After merging, columns present in 'twitter_archive_clean' dataframe\n",
    "twitter_archive_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Add prediction data from `image_predictions` dataframe to `twitter_archive` dataframe.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Define:_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Merge both the dataframes: 'image_predictions' and 'twitter_archive'. \n",
    "\n",
    "*   Then for each tweet id, find the breed of the dog and save it into the list 'breed' and correspondig confidence level in the list 'confidence_level'. \n",
    "\n",
    "*   Add both the lists as columns in original dataframe 'twitter_archive'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Code:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging both the dataframes\n",
    "twitter_archive_clean=twitter_archive_clean.merge(image_predictions_clean,how='inner',on='tweet_id')\n",
    "twitter_archive_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding breed and confidence interval\n",
    "\n",
    "breed=[]\n",
    "confidence_level=[]\n",
    "\n",
    "def breed_and_confidence(dataframe):\n",
    "    \n",
    "    if dataframe['p1_dog'] == True:\n",
    "        breed.append(dataframe['p1'].lower())\n",
    "        confidence_level.append(dataframe['p1_conf'])\n",
    "    elif dataframe['p2_dog'] == True:\n",
    "        breed.append(dataframe['p2'].lower())\n",
    "        confidence_level.append(dataframe['p2_conf'])\n",
    "    elif dataframe['p3_dog'] == True:\n",
    "        breed.append(dataframe['p3'].lower())\n",
    "        confidence_level.append(dataframe['p3_conf'])\n",
    "    else:\n",
    "        breed.append('None')\n",
    "        confidence_level.append(0)\n",
    "        \n",
    "twitter_archive_clean.apply(breed_and_confidence,axis=1)\n",
    "\n",
    "#Adding 'breed' colunn in the dataframe\n",
    "twitter_archive_clean['breed']=breed\n",
    "\n",
    "#Adding 'confidence_level' colunn in the dataframe\n",
    "twitter_archive_clean['confidence_level']=confidence_level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's look at the dataframe \n",
    "twitter_archive_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns in the dataframe\n",
    "twitter_archive_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete extraneous columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Define:_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all the columns which will not be of any use for our exploration.. They are:\n",
    "*   in_reply_to_status_id', \n",
    "*   'in_reply_to_user_id',\n",
    "*   'retweeted_status_id', \n",
    "*   'retweeted_status_user_id',\n",
    "*   'retweeted_status_timestamp', \n",
    "*   'expanded_urls',\n",
    "*   'jpg_url', \n",
    "*   'img_num', \n",
    "*   'p1', \n",
    "*   'p1_conf', \n",
    "*   'p1_dog', \n",
    "*   'p2',\n",
    "*   'p2_conf', \n",
    "*   'p2_dog', \n",
    "*   'p3', \n",
    "*   'p3_conf', \n",
    "*   'p3_dog'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Code:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns in 'twitter_archive_clean' dataframe\n",
    "twitter_archive_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colums which need to be removed\n",
    "del_columns=['in_reply_to_status_id', 'in_reply_to_user_id',\n",
    "       'retweeted_status_id', 'retweeted_status_user_id',\n",
    "       'retweeted_status_timestamp', 'expanded_urls',\n",
    "        'jpg_url', 'img_num', 'p1', 'p1_conf', 'p1_dog', 'p2',\n",
    "       'p2_conf', 'p2_dog', 'p3', 'p3_conf', 'p3_dog']\n",
    "\n",
    "#dropping the columns\n",
    "twitter_archive_clean.drop(columns=del_columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Test:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying columns\n",
    "twitter_archive_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data type needs to be changed of some columns.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Define_:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data type needs to be changed of these columns.\n",
    "\n",
    "*  `tweet_id`: int->str, \n",
    "*  `timestamp`: object->datetime, \n",
    "*  `rating_numerator`: int->float.\n",
    "\n",
    "(Other columns mentioned for this issue in 'Quality Issues' part , have been removed as they were not important to us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Code:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying datatype of columns\n",
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.tweet_id=twitter_archive_clean.tweet_id.astype(str)\n",
    "twitter_archive_clean.timestamp= pd.to_datetime(twitter_archive_clean.timestamp)\n",
    "twitter_archive_clean.rating_numerator=twitter_archive_clean.rating_numerator.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Test:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's check the datatype of all the columns now\n",
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ratings, which were provided with decimal values, are not properly fetched.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Define:_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually fix all the records where rating had been give with decimal values in 'text' columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Code:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying all the records where rating had been given with decimal values in text\n",
    "with pd.option_context('max_colwidth',150):\n",
    "    display(twitter_archive_clean[twitter_archive_clean.text.str.contains(r'(\\d+\\.\\d*\\/\\d+)')].iloc[:,[0,3,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now updating 'rating_numerator' column manually.\n",
    "\n",
    "twitter_archive_clean.loc[(twitter_archive_clean.tweet_id == '883482846933004288'), 'rating_numerator'] = 13.5\n",
    "twitter_archive_clean.loc[(twitter_archive_clean.tweet_id == '786709082849828864'), 'rating_numerator'] = 9.75\n",
    "twitter_archive_clean.loc[(twitter_archive_clean.tweet_id == '778027034220126208'), 'rating_numerator'] = 11.27\n",
    "twitter_archive_clean.loc[(twitter_archive_clean.tweet_id == '680494726643068929'), 'rating_numerator'] = 11.26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Test:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying all the records where rating had been given with decimal values in text\n",
    "with pd.option_context('max_colwidth',150):\n",
    "    display(twitter_archive_clean[twitter_archive_clean.text.str.contains(r'(\\d+\\.\\d*\\/\\d+)')].iloc[:,[0,3,4,5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In some instances, when two fractional parts ( # / #) are given in the text, it takes the first fractional part as rating but it is found found that rating is present in second fractional part.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Define:_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract second fractional part from the text using regular expression and find_all() function and change the value in 'rating_numerator' column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Code:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see how many text have more than one fractional values.\n",
    "with pd.option_context('max_colwidth',150):\n",
    "    display(twitter_archive_clean[twitter_archive_clean.text.str.contains(r'(\\d+\\.?\\d*\\/\\d+).*((\\d+\\.?\\d*\\/\\d+))')].iloc[:,[0,3,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from above result, saving indexes of the rows where ratings are inaccurate\n",
    "indexes_needs_fixing=[798,889,923,1326,1970]\n",
    "\n",
    "#now changing the numerator value for this indexes\n",
    "for i in indexes_needs_fixing:\n",
    "    twitter_archive_clean.loc[i,'rating_numerator']=float(re.findall(r\"\\d+\\.?\\d*\\/\\d+\\.?\\d*\\D+(\\d+\\.?\\d*)\\/\\d+\\.?\\d*\",twitter_archive_clean.loc[i,'text'])[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Test:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see the rows again\n",
    "with pd.option_context('max_colwidth',150):\n",
    "    display(twitter_archive_clean.loc[indexes_needs_fixing])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Errorneous names starting with lowercase letters. For example: a, an, officially etc. need to be removed and set as none.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Define:_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace all the names starting with lowercase letters to 'None'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Code:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[]\n",
    "def name_correction(dataframe):\n",
    "    name=dataframe['name']\n",
    "    if name==name.lower():\n",
    "        names.append('None')\n",
    "    else:\n",
    "        names.append(name)\n",
    "\n",
    "twitter_archive_clean.apply(name_correction,axis=1)\n",
    "twitter_archive_clean['name']=names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Test:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Define:_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources are difficult to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Code:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let'see how values in source column look\n",
    "with pd.option_context('max_colwidth',150):\n",
    "    display(twitter_archive_clean.source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract required part from source\n",
    "twitter_archive_clean['source']=twitter_archive_clean.source.str.extract(r'>(.*)<',expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Test:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'None' values are present in the dataframe instead if null**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Define_:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find columns where 'None' values are present and replace it with null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Code:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking count of non-null values in the dataframe\n",
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking count of 'None' value in 'name' column\n",
    "twitter_archive_clean.name.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking count of 'None' value in 'dog_stages' column\n",
    "twitter_archive_clean.dog_stages.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking count of 'None' value in 'breed' column\n",
    "twitter_archive_clean.breed.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing 'None' values to  null in all 3 columns\n",
    "twitter_archive_clean.name=twitter_archive_clean.name.replace('None',np.nan)\n",
    "twitter_archive_clean.dog_stages=twitter_archive_clean.dog_stages.replace('None',np.nan)\n",
    "twitter_archive_clean.breed=twitter_archive_clean.breed.replace('None',np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking count of non-null values in the dataframe\n",
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.to_csv('twitter_archive_master.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='analyzing'></a>\n",
    "### (IV) Analyzing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) How does tweet distribution look like year and month wise?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping the dataset by 'year' and 'month'\n",
    "grouped=twitter_archive_clean.groupby([twitter_archive_clean.timestamp.dt.year,twitter_archive_clean.timestamp.dt.month])['tweet_id'].count()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up position values on x and y axis for plotting a graph\n",
    "y_pos=[y for y in grouped]\n",
    "x_pos=np.arange(1,len(y_pos)+1)\n",
    "x_ticks=list(twitter_archive_clean.groupby([twitter_archive_clean.timestamp.dt.year,twitter_archive_clean.timestamp.dt.month]).groups.keys())\n",
    "x_ticks=[str(x) for x in x_ticks]\n",
    "x_ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plotting the graph\n",
    "\n",
    "plt.figure(figsize=(25,8))\n",
    "plt.bar(x_pos,y_pos,tick_label=x_ticks)\n",
    "plt.xlabel('(Year,month)');\n",
    "plt.ylabel('No. of tweets');\n",
    "plt.title('Month, Year vs No. of Tweets');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) What is the repartition of the dog stages?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogstages_count = twitter_archive_clean.dog_stages.value_counts()\n",
    "dogstages_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a pie chart.\n",
    "explode = np.linspace(0,.1,4)\n",
    "colors = ['#52BE80', '#E59866', '#EC7063','#5DADE2']\n",
    "dogstages_count.sort_values(ascending=True).plot.pie(legend=True, subplots=True, autopct='%.2f%%', figsize=(8,8), explode=explode,colors = colors);\n",
    "plt.ylabel('')\n",
    "plt.title('Repartition of dog stages', weight='bold', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Which breed has got more likes and how retweet counts look like for those breeds?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping by breed and finding total number of likes for each breed.\n",
    "breed_likes=twitter_archive_clean.groupby('breed')['favorite_count'].sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "#saving the index of the result\n",
    "index=breed_likes.index\n",
    "\n",
    "breed_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping by breed and finding total number of retweets for each breed\n",
    "breed_retweets=twitter_archive_clean.groupby('breed')['retweet_count'].sum().sort_values(ascending=False)\n",
    "\n",
    "#consideing the only breeds which were present in top 8 most liked breeds\n",
    "breed_retweets=breed_retweets.loc[index]\n",
    "\n",
    "breed_retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a graph.\n",
    "\n",
    "fig=plt.figure()\n",
    "ax = fig.add_subplot(111) # Creates matplotlib axes\n",
    "ax2 = ax.twinx() # Creates another axes that shares the same x-axis as ax.\n",
    "width = 0.4\n",
    "breed_likes.plot(figsize = (10,6), kind='bar', color='#C0392B', ax=ax, width=width, position=1, title='Popular Breeds: Likes vs. Retweets')\n",
    "breed_retweets.plot(figsize = (10,6), kind='bar', color='#3498DB', ax=ax2, width=width, position=0)\n",
    "\n",
    "ax.set_ylabel('Likes')\n",
    "ax2.set_ylabel('Retweets')\n",
    "\n",
    "ax.set_xticklabels(index, rotation=60)\n",
    "\n",
    "h1, l1 = ax.get_legend_handles_labels()\n",
    "h2, l2 = ax2.get_legend_handles_labels()\n",
    "\n",
    "plt.legend(h1+h2, l1+l2, loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Where do the tweets come from?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_count=twitter_archive_clean.source.value_counts()\n",
    "source_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating pie chart\n",
    "\n",
    "explode = np.linspace(0,.3,3)\n",
    "colors = ['#52BE80', '#E59866', '#EC7063']\n",
    "source_count.sort_values(ascending=True).plot.pie(legend=True, subplots=True, autopct='%.2f%%', figsize=(8,8), explode=explode,colors = colors);\n",
    "plt.ylabel('')\n",
    "plt.title('Repartition of source', weight='bold', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Is there any relationship between likes and retweets?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.plot(kind = 'scatter', x = 'favorite_count', y = 'retweet_count', alpha = 0.5,figsize=(15,6))\n",
    "plt.xlabel('Likes')\n",
    "plt.ylabel('Retweets')\n",
    "plt.title('Relationship between Retweets & Likes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
